import Foundation
import os

/// OpenAI Compatible Provider
/// å…¼å®¹ OpenAI API æ ¼å¼çš„é€šç”¨å®ç°
/// æ”¯æŒ: OpenAI, Groq, OpenRouter, Ollama, ç­‰
actor OpenAICompatibleProvider: LLMProvider {
    
    // MARK: - Properties
    
    private let logger = Logger(subsystem: "com.spokeanywhere", category: "LLM")
    
    let providerType: LLMProviderType
    private let config: ProviderConfig
    private let session: URLSession
    
    /// è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    private let timeout: TimeInterval = 30
    
    // MARK: - Init
    
    init(providerType: LLMProviderType, config: ProviderConfig) {
        self.providerType = providerType
        self.config = config
        
        let configuration = URLSessionConfiguration.default
        configuration.timeoutIntervalForRequest = timeout
        configuration.timeoutIntervalForResource = timeout
        self.session = URLSession(configuration: configuration)
    }
    
    // MARK: - LLMProvider
    
    nonisolated var isConfigured: Bool {
        // æ£€æŸ¥å¿…è¦é…ç½®
        guard !config.baseURL.isEmpty, !config.modelName.isEmpty else {
            return false
        }
        
        // éœ€è¦ API Key çš„ Provider æ£€æŸ¥ Keychain
        if providerType.requiresAPIKey {
            guard let keyRef = config.apiKeyRef,
                  KeychainService.exists(key: keyRef) else {
                return false
            }
        }
        
        return true
    }
    
    func complete(prompt: LLMPrompt) async throws -> LLMResponse {
        guard isConfigured else {
            throw LLMError.notConfigured
        }
        
        let request = try buildRequest(prompt: prompt)
        
        logger.info("ğŸ¤– LLM request to \(self.providerType.displayName)")
        
        do {
            let (data, response) = try await session.data(for: request)
            
            guard let httpResponse = response as? HTTPURLResponse else {
                throw LLMError.invalidResponse
            }
            
            // å¤„ç†é”™è¯¯çŠ¶æ€ç 
            switch httpResponse.statusCode {
            case 200...299:
                break
            case 401:
                throw LLMError.invalidAPIKey
            case 429:
                throw LLMError.rateLimited
            default:
                let message = String(data: data, encoding: .utf8)
                throw LLMError.serverError(httpResponse.statusCode, message)
            }
            
            return try parseResponse(data: data)
            
        } catch let error as LLMError {
            throw error
        } catch let error as URLError where error.code == .timedOut {
            throw LLMError.timeout
        } catch {
            throw LLMError.networkError(error)
        }
    }
    
    func testConnection() async -> Bool {
        // å‘é€ä¸€ä¸ªç®€å•çš„æµ‹è¯•è¯·æ±‚
        let testPrompt = LLMPrompt(
            systemPrompt: "You are a helpful assistant.",
            userMessage: "Say 'OK' if you can hear me."
        )
        
        do {
            let response = try await complete(prompt: testPrompt)
            return !response.text.isEmpty
        } catch {
            logger.error("âŒ Connection test failed: \(error.localizedDescription)")
            return false
        }
    }
    
    // MARK: - Private
    
    private func buildRequest(prompt: LLMPrompt) throws -> URLRequest {
        // æ„å»º URL
        let baseURL = config.baseURL.trimmingCharacters(in: CharacterSet(charactersIn: "/"))
        guard let url = URL(string: "\(baseURL)/chat/completions") else {
            throw LLMError.invalidResponse
        }
        
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
        
        // æ·»åŠ  API Key
        if let keyRef = config.apiKeyRef,
           let apiKey = KeychainService.load(key: keyRef) {
            request.setValue("Bearer \(apiKey)", forHTTPHeaderField: "Authorization")
        }
        
        // æ„å»ºè¯·æ±‚ä½“
        var messages: [[String: String]] = []
        
        // System prompt
        if !prompt.systemPrompt.isEmpty {
            messages.append([
                "role": "system",
                "content": prompt.systemPrompt
            ])
        }
        
        // User message
        messages.append([
            "role": "user",
            "content": prompt.userMessage
        ])
        
        let body: [String: Any] = [
            "model": config.modelName,
            "messages": messages,
            "temperature": 0.7,
            "max_tokens": 2048
        ]
        
        request.httpBody = try JSONSerialization.data(withJSONObject: body)
        
        return request
    }
    
    private func parseResponse(data: Data) throws -> LLMResponse {
        // è§£æ OpenAI æ ¼å¼å“åº”
        guard let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any],
              let choices = json["choices"] as? [[String: Any]],
              let firstChoice = choices.first,
              let message = firstChoice["message"] as? [String: Any],
              let content = message["content"] as? String else {
            logger.error("âŒ Failed to parse response: \(String(data: data, encoding: .utf8) ?? "nil")")
            throw LLMError.invalidResponse
        }
        
        let trimmedContent = content.trimmingCharacters(in: .whitespacesAndNewlines)
        
        if trimmedContent.isEmpty {
            throw LLMError.emptyResponse
        }
        
        // è§£æ usageï¼ˆå¯é€‰ï¼‰
        var usage: TokenUsage?
        if let usageJson = json["usage"] as? [String: Any] {
            usage = TokenUsage(
                promptTokens: usageJson["prompt_tokens"] as? Int,
                completionTokens: usageJson["completion_tokens"] as? Int,
                totalTokens: usageJson["total_tokens"] as? Int
            )
        }
        
        logger.info("âœ… LLM response received (\(trimmedContent.count) chars)")
        
        return LLMResponse(text: trimmedContent, usage: usage)
    }
}
