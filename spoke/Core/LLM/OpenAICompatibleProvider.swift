import Foundation
import os

/// OpenAI Compatible Provider
/// å…¼å®¹ OpenAI API æ ¼å¼çš„é€šç”¨å®ç°
/// æ”¯æŒ: OpenAI, Groq, OpenRouter, Ollama, ç­‰
actor OpenAICompatibleProvider: LLMProvider {
    
    // MARK: - Properties
    
    private let logger = Logger(subsystem: "com.spokeanywhere", category: "LLM")
    
    let providerType: LLMProviderType
    private let config: ProviderConfig
    private let profile: ProviderProfile?
    private let providedAPIKey: String? // ç›´æ¥ä¼ å…¥çš„ API Key
    private let session: URLSession
    
    /// è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    private let timeout: TimeInterval = 30
    
    // MARK: - Computed (ä» Profile æˆ– Config è·å–)
    
    private var baseURL: String {
        profile?.baseURL ?? config.baseURL
    }
    
    private var modelName: String {
        profile?.modelName ?? config.modelName
    }
    
    // è¿™é‡Œçš„ apiKeyRef ä»…ç”¨äºæ—§ç‰ˆå…¼å®¹
    private var apiKeyRef: String? {
        profile?.apiKeyRef ?? config.apiKeyRef
    }
    
    private var temperature: Double {
        profile?.temperature ?? 0.3
    }
    
    private var maxTokens: Int {
        profile?.maxTokens ?? 2048
    }
    
    // MARK: - Init
    
    /// æ—§ç‰ˆåˆå§‹åŒ– (ä» ProviderConfig)
    init(providerType: LLMProviderType, config: ProviderConfig) {
        self.providerType = providerType
        self.config = config
        self.profile = nil
        self.providedAPIKey = nil
        
        let configuration = URLSessionConfiguration.default
        configuration.timeoutIntervalForRequest = timeout
        configuration.timeoutIntervalForResource = timeout
        self.session = URLSession(configuration: configuration)
    }
    
    /// æ–°ç‰ˆåˆå§‹åŒ– (ä» ProviderProfile)
    /// - apiKey: å¯é€‰ï¼Œç›´æ¥ä¼ å…¥ API Keyï¼Œé¿å… Provider å†…éƒ¨è®¿é—® Keychain
    init(profile: ProviderProfile, apiKey: String? = nil) {
        self.providerType = profile.providerType
        self.profile = profile
        self.providedAPIKey = apiKey
        // åˆ›å»ºä¸€ä¸ªç©ºçš„ config ä½œä¸º fallback
        self.config = ProviderConfig(baseURL: profile.baseURL, modelName: profile.modelName, apiKeyRef: profile.apiKeyRef)
        
        let configuration = URLSessionConfiguration.default
        configuration.timeoutIntervalForRequest = timeout
        configuration.timeoutIntervalForResource = timeout
        self.session = URLSession(configuration: configuration)
    }
    
    // MARK: - LLMProvider
    
    nonisolated var isConfigured: Bool {
        // ä¼˜å…ˆæ£€æŸ¥ Profile
        let url = profile?.baseURL ?? config.baseURL
        let model = profile?.modelName ?? config.modelName
        
        // æ£€æŸ¥å¿…è¦é…ç½®
        guard !url.isEmpty, !model.isEmpty else {
            return false
        }
        
        // å¦‚æœç›´æ¥æä¾›äº† API Keyï¼Œåˆ™è®¤ä¸ºå·²é…ç½®
        if let apiKey = providedAPIKey, !apiKey.isEmpty {
            return true
        }
        
        // ä¸éœ€è¦ API Key çš„ Provider (å¦‚ Ollama)
        if !providerType.requiresAPIKey {
            return true
        }
        
        // éœ€è¦ API Key ä½†æ²¡æœ‰æä¾›
        return false
    }
    
    func complete(prompt: LLMPrompt) async throws -> LLMResponse {
        guard isConfigured else {
            throw LLMError.notConfigured
        }
        
        let request = try buildRequest(prompt: prompt)
        
        logger.info("ğŸ¤– LLM request to \(self.providerType.displayName)")
        
        do {
            let (data, response) = try await session.data(for: request)
            
            guard let httpResponse = response as? HTTPURLResponse else {
                throw LLMError.invalidResponse
            }
            
            // å¤„ç†é”™è¯¯çŠ¶æ€ç 
            switch httpResponse.statusCode {
            case 200...299:
                break
            case 401:
                throw LLMError.invalidAPIKey
            case 429:
                throw LLMError.rateLimited
            default:
                let message = String(data: data, encoding: .utf8)
                throw LLMError.serverError(httpResponse.statusCode, message)
            }
            
            return try parseResponse(data: data)
            
        } catch let error as LLMError {
            throw error
        } catch let error as URLError where error.code == .timedOut {
            throw LLMError.timeout
        } catch {
            throw LLMError.networkError(error)
        }
    }
    
    func testConnection() async throws -> Bool {
        // å‘é€ä¸€ä¸ªç®€å•çš„æµ‹è¯•è¯·æ±‚
        let testPrompt = LLMPrompt(
            systemPrompt: "You are a helpful assistant.",
            userMessage: "Say 'OK' if you can hear me."
        )
        
        do {
            let response = try await complete(prompt: testPrompt)
            return !response.text.isEmpty
        } catch let error as LLMError {
            logger.error("âŒ Connection test failed (LLMError): \(error.localizedDescription)")
            throw error // æŠ›å‡ºå…·ä½“é”™è¯¯ä¾› UI æ˜¾ç¤º
        } catch {
            logger.error("âŒ Connection test failed: \(error.localizedDescription)")
            throw error
        }
    }
    
    /// è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
    /// æ”¯æŒä¸åŒ Provider çš„ API æ ¼å¼å·®å¼‚
    func fetchModels() async -> [String] {
        let urlString = baseURL.trimmingCharacters(in: CharacterSet(charactersIn: "/"))
        
        // ä½¿ç”¨ providedAPIKeyï¼ˆç”± LLMSettings æ³¨å…¥ï¼‰
        let apiKey = providedAPIKey
        
        // æ ¹æ® provider ç±»å‹æ„å»º URL å’Œè¯·æ±‚
        let modelsURL: URL?
        var authHeader: (String, String)?
        
        switch providerType {
        case .googleGemini:
            // Gemini: GET /models?key={apiKey}
            // å“åº”: { models: [{ name: "models/gemini-1.5-flash" }] }
            if let key = apiKey {
                modelsURL = URL(string: "\(urlString)/models?key=\(key)")
            } else {
                modelsURL = URL(string: "\(urlString)/models")
            }
            
        case .anthropic:
            // Anthropic: GET /v1/models, Header: x-api-key
            // å“åº”: { data: [{ id: "claude-3-opus-20240229" }] }
            modelsURL = URL(string: "\(urlString)/models")
            if let key = apiKey {
                authHeader = ("x-api-key", key)
            }
            
        case .ollama:
            // Ollama: GET /api/tags (ä¸æ˜¯ /models)
            // å“åº”: { models: [{ name: "llama3:latest" }] }
            modelsURL = URL(string: "\(urlString.replacingOccurrences(of: "/v1", with: ""))/api/tags")
            
        case .openRouter:
            // OpenRouter: GET /api/v1/models, Header: Authorization Bearer
            // å“åº”: { data: [{ id: "openai/gpt-4" }] }
            modelsURL = URL(string: "\(urlString)/models")
            if let key = apiKey {
                authHeader = ("Authorization", "Bearer \(key)")
            }
            
        case .groq:
            // Groq: GET /openai/v1/models, Header: Authorization Bearer
            // å“åº”: { data: [{ id: "llama-3.1-70b-versatile" }] }
            modelsURL = URL(string: "\(urlString)/models")
            if let key = apiKey {
                authHeader = ("Authorization", "Bearer \(key)")
            }
            
        case .openai, .openAICompatible:
            // OpenAI æ ‡å‡†: GET /models, Header: Authorization Bearer
            // å“åº”: { data: [{ id: "gpt-4" }] }
            modelsURL = URL(string: "\(urlString)/models")
            if let key = apiKey {
                authHeader = ("Authorization", "Bearer \(key)")
            }
        }
        
        guard let url = modelsURL else {
            logger.warning("âš ï¸ Invalid URL for models endpoint")
            return []
        }
        
        var request = URLRequest(url: url)
        request.httpMethod = "GET"
        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
        request.timeoutInterval = 10
        
        // æ·»åŠ è®¤è¯å¤´
        if let (headerName, headerValue) = authHeader {
            request.setValue(headerValue, forHTTPHeaderField: headerName)
        }
        
        // Anthropic éœ€è¦é¢å¤–çš„ç‰ˆæœ¬å¤´
        if providerType == .anthropic {
            request.setValue("2023-06-01", forHTTPHeaderField: "anthropic-version")
        }
        
        do {
            let (data, response) = try await session.data(for: request)
            
            guard let httpResponse = response as? HTTPURLResponse,
                  (200...299).contains(httpResponse.statusCode) else {
                let statusCode = (response as? HTTPURLResponse)?.statusCode ?? 0
                logger.warning("âš ï¸ Models endpoint returned status \(statusCode)")
                return []
            }
            
            return parseModelsResponse(data: data)
            
        } catch {
            logger.warning("âš ï¸ Failed to fetch models: \(error.localizedDescription)")
            return []
        }
    }
    
    /// è§£æä¸åŒæ ¼å¼çš„ models å“åº”
    private func parseModelsResponse(data: Data) -> [String] {
        guard let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any] else {
            logger.warning("âš ï¸ Failed to parse models response as JSON")
            return []
        }
        
        var models: [String] = []
        
        switch providerType {
        case .googleGemini:
            // Gemini: { models: [{ name: "models/gemini-1.5-flash", ... }] }
            if let modelsArray = json["models"] as? [[String: Any]] {
                models = modelsArray.compactMap { model -> String? in
                    guard let name = model["name"] as? String else { return nil }
                    // è¿‡æ»¤æ‰ embedding æ¨¡å‹ï¼Œåªä¿ç•™ç”Ÿæˆæ¨¡å‹
                    if name.contains("embedding") { return nil }
                    return name.replacingOccurrences(of: "models/", with: "")
                }
            }
            
        case .ollama:
            // Ollama: { models: [{ name: "llama3:latest", ... }] }
            if let modelsArray = json["models"] as? [[String: Any]] {
                models = modelsArray.compactMap { $0["name"] as? String }
            }
            
        case .openai, .anthropic, .groq, .openRouter, .openAICompatible:
            // OpenAI æ ‡å‡†æ ¼å¼: { data: [{ id: "gpt-4", ... }] }
            if let dataArray = json["data"] as? [[String: Any]] {
                models = dataArray.compactMap { $0["id"] as? String }
            }
        }
        
        if models.isEmpty {
            logger.warning("âš ï¸ No models found in response")
        } else {
            logger.info("âœ… Fetched \(models.count) models from \(self.providerType.displayName)")
        }
        
        return models.sorted()
    }
    
    // MARK: - Private
    
    private func buildRequest(prompt: LLMPrompt) throws -> URLRequest {
        let urlString = baseURL.trimmingCharacters(in: CharacterSet(charactersIn: "/"))
        
        // ä½¿ç”¨ providedAPIKeyï¼ˆç”± LLMSettings æ³¨å…¥ï¼‰
        let apiKey = providedAPIKey
        
        if providerType == .googleGemini {
            return try buildGeminiRequest(urlString: urlString, apiKey: apiKey, prompt: prompt)
        }
        
        // OpenAI Compatible Request
        guard let url = URL(string: "\(urlString)/chat/completions") else {
            throw LLMError.invalidResponse
        }
        
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
        
        // æ·»åŠ  API Key
        if let key = apiKey {
            request.setValue("Bearer \(key)", forHTTPHeaderField: "Authorization")
        }
        
        // Anthropic éœ€è¦é¢å¤–çš„ç‰ˆæœ¬å¤´
        if providerType == .anthropic {
            request.setValue("2023-06-01", forHTTPHeaderField: "anthropic-version")
            request.setValue(apiKey, forHTTPHeaderField: "x-api-key")
            // Anthropic ä¸ä½¿ç”¨ Bearer Token
            request.setValue(nil, forHTTPHeaderField: "Authorization")
        }
        
        // æ„å»ºè¯·æ±‚ä½“
        var messages: [[String: String]] = []
        
        // System prompt
        if !prompt.systemPrompt.isEmpty {
            messages.append([
                "role": "system",
                "content": prompt.systemPrompt
            ])
        }
        
        // User message
        messages.append([
            "role": "user",
            "content": prompt.userMessage
        ])
        
        let body: [String: Any] = [
            "model": modelName,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": maxTokens
        ]
        
        request.httpBody = try JSONSerialization.data(withJSONObject: body)
        
        return request
    }
    
    private func buildGeminiRequest(urlString: String, apiKey: String?, prompt: LLMPrompt) throws -> URLRequest {
        // Gemini: POST /models/{model}:generateContent?key={apiKey}
        guard let key = apiKey else { throw LLMError.invalidAPIKey }
        
        let model = modelName.isEmpty ? "gemini-pro" : modelName
        // å¤„ç†å¯èƒ½åŒ…å« "models/" å‰ç¼€çš„æƒ…å†µ
        let cleanModelName = model.replacingOccurrences(of: "models/", with: "")
        
        guard let url = URL(string: "\(urlString)/models/\(cleanModelName):generateContent?key=\(key)") else {
            throw LLMError.invalidResponse
        }
        
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
        
        // æ„å»º Gemini è¯·æ±‚ä½“
        // {
        //   "contents": [{ "role": "user", "parts": [{ "text": "..." }] }],
        //   "systemInstruction": { "parts": [{ "text": "..." }] },
        //   "generationConfig": { ... }
        // }
        
        var body: [String: Any] = [
            "contents": [
                [
                    "role": "user",
                    "parts": [
                        ["text": prompt.userMessage]
                    ]
                ]
            ],
            "generationConfig": [
                "temperature": temperature,
                "maxOutputTokens": maxTokens
            ]
        ]
        
        if !prompt.systemPrompt.isEmpty {
            body["systemInstruction"] = [
                "parts": [
                    ["text": prompt.systemPrompt]
                ]
            ]
        }
        
        request.httpBody = try JSONSerialization.data(withJSONObject: body)
        return request
    }
    
    private func parseResponse(data: Data) throws -> LLMResponse {
        if providerType == .googleGemini {
            return try parseGeminiResponse(data: data)
        }
        
        // è§£æ OpenAI æ ¼å¼å“åº”
        guard let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any] else {
            throw LLMError.invalidResponse
        }
        
        // æ£€æŸ¥ Anthropic é”™è¯¯æ ¼å¼
        if let error = json["error"] as? [String: Any], let message = error["message"] as? String {
            throw LLMError.serverError(400, message)
        }
        
        // å…¼å®¹ Anthropic å“åº”æ ¼å¼ (content æ˜¯æ•°ç»„)
        if let contentArray = json["content"] as? [[String: Any]],
           let firstContent = contentArray.first,
           let text = firstContent["text"] as? String {
            return LLMResponse(text: text.trimmingCharacters(in: .whitespacesAndNewlines), usage: nil)
        }
        
        // æ ‡å‡† OpenAI æ ¼å¼
        if let choices = json["choices"] as? [[String: Any]],
           let firstChoice = choices.first,
           let message = firstChoice["message"] as? [String: Any],
           let content = message["content"] as? String {
            
            let trimmedContent = content.trimmingCharacters(in: .whitespacesAndNewlines)
            if trimmedContent.isEmpty { throw LLMError.emptyResponse }
            
            // è§£æ usage
            var usage: TokenUsage?
            if let usageJson = json["usage"] as? [String: Any] {
                usage = TokenUsage(
                    promptTokens: usageJson["prompt_tokens"] as? Int,
                    completionTokens: usageJson["completion_tokens"] as? Int,
                    totalTokens: usageJson["total_tokens"] as? Int
                )
            }
            
            logger.info("âœ… LLM response received (\(trimmedContent.count) chars)")
            return LLMResponse(text: trimmedContent, usage: usage)
        }
        
        logger.error("âŒ Failed to parse response: \(String(data: data, encoding: .utf8) ?? "nil")")
        throw LLMError.invalidResponse
    }
    
    private func parseGeminiResponse(data: Data) throws -> LLMResponse {
        // Gemini: { "candidates": [{ "content": { "parts": [{ "text": "..." }] } }] }
        guard let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any] else {
            throw LLMError.invalidResponse
        }
        
        // æ£€æŸ¥é”™è¯¯
        if let error = json["error"] as? [String: Any], let message = error["message"] as? String {
            throw LLMError.serverError(400, message)
        }
        
        guard let candidates = json["candidates"] as? [[String: Any]],
              let firstCandidate = candidates.first,
              let content = firstCandidate["content"] as? [String: Any],
              let parts = content["parts"] as? [[String: Any]],
              let firstPart = parts.first,
              let text = firstPart["text"] as? String else {
            logger.error("âŒ Failed to parse Gemini response: \(String(data: data, encoding: .utf8) ?? "nil")")
            throw LLMError.invalidResponse
        }
        
        let trimmedContent = text.trimmingCharacters(in: .whitespacesAndNewlines)
        logger.info("âœ… Gemini response received (\(trimmedContent.count) chars)")
        
        return LLMResponse(text: trimmedContent, usage: nil)
    }
}
