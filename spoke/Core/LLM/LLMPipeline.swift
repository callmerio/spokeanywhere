import Foundation
import os

/// LLM å¤„ç†ç®¡çº¿
/// è´Ÿè´£åè°ƒè½¬å†™æ–‡æœ¬çš„ LLM ç²¾ç‚¼å¤„ç†
@MainActor
final class LLMPipeline {
    
    // MARK: - Singleton
    
    static let shared = LLMPipeline()
    
    private let logger = Logger(subsystem: "com.spokeanywhere", category: "LLMPipeline")
    
    // MARK: - Dependencies
    
    private let settings = LLMSettings.shared
    private let contextService = ContextService.shared
    private let clipboardHistory = ClipboardHistoryService.shared
    
    // MARK: - Properties
    
    /// å½“å‰æ˜¯å¦æ­£åœ¨å¤„ç†
    private(set) var isProcessing = false
    
    // MARK: - Init
    
    private init() {}
    
    // MARK: - Public API
    
    /// æ£€æŸ¥æ˜¯å¦éœ€è¦ LLM å¤„ç†
    var shouldProcess: Bool {
        settings.isFullyConfigured
    }
    
    /// å¯¹è¯ï¼ˆQuick Ask ä¸“ç”¨ï¼‰
    /// - Parameter message: ç”¨æˆ·æ¶ˆæ¯
    /// - Returns: AI å›ç­”
    func chat(_ message: String) async -> Result<String, LLMError> {
        guard shouldProcess else {
            logger.info("â­ï¸ LLM not configured")
            return .failure(.notConfigured)
        }
        
        guard let provider = settings.createCurrentProvider() else {
            logger.error("âŒ Failed to create LLM provider")
            return .failure(.notConfigured)
        }
        
        isProcessing = true
        defer { isProcessing = false }
        
        // Quick Ask ä¸“ç”¨ç³»ç»Ÿæç¤ºè¯
        let systemPrompt = """
        ä½ æ˜¯ä¸€ä¸ªå‹å¥½ã€ä¸“ä¸šçš„ AI åŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜æä¾›æ¸…æ™°ã€å‡†ç¡®çš„å›ç­”ã€‚
        
        å¦‚æœç”¨æˆ·æä¾›äº†è¯­éŸ³è½¬å†™å†…å®¹ï¼Œè¯·æ³¨æ„ï¼š
        - è¯­éŸ³è½¬å†™å¯èƒ½å­˜åœ¨é”™è¯¯ï¼ˆå°¤å…¶æ˜¯ä¸“ä¸šæœ¯è¯­ã€äººåã€äº§å“åï¼‰
        - è¯·æ ¹æ®ä¸Šä¸‹æ–‡æ¨æ–­ç”¨æˆ·çš„çœŸå®æ„å›¾
        - å¦‚æœä¸ç¡®å®šç”¨æˆ·çš„æ„æ€ï¼Œå¯ä»¥ç¤¼è²Œåœ°è¯¢é—®
        
        å›ç­”è¦æ±‚ï¼š
        - ä½¿ç”¨ç®€æ´æ˜äº†çš„è¯­è¨€
        - é€‚å½“ä½¿ç”¨åˆ—è¡¨æˆ–åˆ†æ®µæ¥ç»„ç»‡å†…å®¹
        - å¦‚æœæ˜¯ä»£ç ç›¸å…³é—®é¢˜ï¼Œè¯·æä¾›ä»£ç ç¤ºä¾‹
        """
        
        let prompt = LLMPrompt(
            systemPrompt: systemPrompt,
            userMessage: message,
            contextAppName: contextService.getCurrentTargetApp()?.name
        )
        
        logger.info("ğŸ¤– Quick Ask: \(message.prefix(100))...")
        
        do {
            let response = try await provider.complete(prompt: prompt)
            logger.info("âœ… Quick Ask complete")
            return .success(response.text)
        } catch let error as LLMError {
            logger.error("âŒ Quick Ask error: \(error.localizedDescription)")
            return .failure(error)
        } catch {
            logger.error("âŒ Unexpected error: \(error.localizedDescription)")
            return .failure(.networkError(error))
        }
    }
    
    /// ç²¾ç‚¼æ–‡æœ¬
    /// - Parameters:
    ///   - text: åŸå§‹è½¬å†™æ–‡æœ¬
    ///   - customSystemPrompt: è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯ï¼ˆç”¨äºå†å²è®°å½•é‡å¤„ç†ï¼‰
    /// - Returns: ç²¾ç‚¼åçš„æ–‡æœ¬ï¼Œå¤±è´¥æ—¶è¿”å›é”™è¯¯
    func refine(_ text: String, customSystemPrompt: String? = nil) async -> Result<String, LLMError> {
        guard shouldProcess else {
            logger.info("â­ï¸ LLM not configured, skipping")
            return .success(text)
        }
        
        guard let provider = settings.createCurrentProvider() else {
            logger.error("âŒ Failed to create LLM provider")
            return .failure(.notConfigured)
        }
        
        isProcessing = true
        defer { isProcessing = false }
        
        // æ„å»º Promptï¼ˆæ”¯æŒè‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯ï¼‰
        let prompt: LLMPrompt
        if let customPrompt = customSystemPrompt {
            // ä½¿ç”¨è‡ªå®šä¹‰æç¤ºè¯ï¼ˆå†å²è®°å½•é‡å¤„ç†åœºæ™¯ï¼‰
            prompt = LLMPrompt(
                systemPrompt: customPrompt,
                userMessage: text,
                contextAppName: nil
            )
        } else {
            // ä½¿ç”¨é»˜è®¤è®¾ç½®æ„å»ºæç¤ºè¯
            prompt = buildPrompt(for: text)
        }
        
        // è°ƒè¯•ï¼šæ‰“å°å®Œæ•´ Prompt
        logger.info("ğŸ¤– Starting LLM refinement...")
        print("ğŸ“ === LLM PROMPT DEBUG ===")
        print("ğŸ“ System Prompt:")
        print(prompt.systemPrompt)
        print("ğŸ“ User Message: \(prompt.userMessage)")
        print("ğŸ“ === END PROMPT ===")
        
        do {
            let response = try await provider.complete(prompt: prompt)
            logger.info("âœ… LLM refinement complete")
            return .success(response.text)
        } catch let error as LLMError {
            logger.error("âŒ LLM error: \(error.localizedDescription)")
            return .failure(error)
        } catch {
            logger.error("âŒ Unexpected error: \(error.localizedDescription)")
            return .failure(.networkError(error))
        }
    }
    
    // MARK: - Private
    
    private func buildPrompt(for text: String) -> LLMPrompt {
        var systemPrompt = settings.systemPrompt
        
        // æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
        if settings.includeActiveApp {
            if let appName = contextService.getCurrentTargetApp()?.name {
                systemPrompt += "\n\nå½“å‰åº”ç”¨: \(appName)"
            }
        }
        
        if settings.includeClipboard {
            // é™åˆ¶ä¸ºæœ€è¿‘ 10 æ¡ï¼Œå‡å°‘å™ªéŸ³å¹¶èšç„¦æœ€è¿‘ä¸Šä¸‹æ–‡
            let historyContext = clipboardHistory.formatForPrompt(limit: 10)
            if !historyContext.isEmpty {
                systemPrompt += "\n\n" + historyContext
            }
        }
        
        return LLMPrompt(
            systemPrompt: systemPrompt,
            userMessage: text,
            contextAppName: contextService.getCurrentTargetApp()?.name
        )
    }
}
