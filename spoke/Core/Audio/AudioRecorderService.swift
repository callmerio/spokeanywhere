import AVFoundation
import Speech
import os

/// éŸ³é¢‘å½•åˆ¶æœåŠ¡
/// è´Ÿè´£éº¦å…‹é£å½•éŸ³ã€æµå¼å†™å…¥ç£ç›˜ã€å®æ—¶è½¬å†™
@MainActor
final class AudioRecorderService: NSObject {
    
    // MARK: - Constants
    
    /// SFSpeechRecognizer å–æ¶ˆé”™è¯¯ç 
    private static let speechRecognizerCancelledErrorCode = 216
    
    // MARK: - Singleton
    
    static let shared = AudioRecorderService()
    
    private let logger = Logger(subsystem: "com.spokeanywhere", category: "Audio")
    
    // MARK: - Properties
    
    private var audioEngine: AVAudioEngine?
    private var recognitionRequest: SFSpeechAudioBufferRecognitionRequest?
    /// å½“å‰è¯†åˆ«ä»»åŠ¡ï¼ˆå¤–éƒ¨å¯è¯»å–ä»¥æ£€æŸ¥å®ŒæˆçŠ¶æ€ï¼‰
    private(set) var recognitionTask: SFSpeechRecognitionTask?
    private let speechRecognizer = SFSpeechRecognizer(locale: Locale(identifier: "zh-CN"))
    
    /// ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶ URL
    private var tempAudioFileURL: URL?
    private var audioFile: AVAudioFile?
    
    /// æ˜¯å¦æ­£åœ¨å½•éŸ³
    private(set) var isRecording = false
    
    /// å›è°ƒ
    var onAudioLevelUpdate: ((Float) -> Void)?
    var onPartialResult: ((String) -> Void)?
    var onFinalResult: ((String) -> Void)?
    var onError: ((Error) -> Void)?
    
    // MARK: - Init
    
    private override init() {
        super.init()
    }
    
    // MARK: - Public API
    
    /// è¯·æ±‚éº¦å…‹é£å’Œè¯­éŸ³è¯†åˆ«æƒé™
    func requestPermissions() async -> Bool {
        // éº¦å…‹é£æƒé™
        let micStatus = await withCheckedContinuation { continuation in
            AVCaptureDevice.requestAccess(for: .audio) { granted in
                continuation.resume(returning: granted)
            }
        }
        
        guard micStatus else {
            print("âš ï¸ Microphone permission denied")
            return false
        }
        
        // è¯­éŸ³è¯†åˆ«æƒé™
        let speechStatus = await withCheckedContinuation { continuation in
            SFSpeechRecognizer.requestAuthorization { status in
                continuation.resume(returning: status == .authorized)
            }
        }
        
        guard speechStatus else {
            print("âš ï¸ Speech recognition permission denied")
            return false
        }
        
        print("âœ… All audio permissions granted")
        return true
    }
    
    /// å¼€å§‹å½•éŸ³
    func startRecording() throws {
        guard !isRecording else { return }
        
        // ç¡®ä¿æœ‰å¯ç”¨çš„è¯­éŸ³è¯†åˆ«å™¨
        guard let recognizer = speechRecognizer, recognizer.isAvailable else {
            throw AudioRecorderError.recognizerNotAvailable
        }
        
        // åˆ›å»ºéŸ³é¢‘å¼•æ“
        audioEngine = AVAudioEngine()
        guard let audioEngine = audioEngine else {
            throw AudioRecorderError.engineCreationFailed
        }
        
        // åˆ›å»ºè¯†åˆ«è¯·æ±‚
        recognitionRequest = SFSpeechAudioBufferRecognitionRequest()
        guard let request = recognitionRequest else {
            throw AudioRecorderError.requestCreationFailed
        }
        
        request.shouldReportPartialResults = true
        request.addsPunctuation = true
        // ä½¿ç”¨ dictation æ¨¡å¼ï¼Œå‡å°‘"æ™ºèƒ½ä¿®æ­£"ï¼Œä¿ç•™æ›´å¤šåŸå§‹è¡¨è¾¾
        request.taskHint = .dictation
        
        // åˆ›å»ºä¸´æ—¶æ–‡ä»¶ç”¨äºä¿å­˜éŸ³é¢‘
        tempAudioFileURL = createTempAudioFileURL()
        
        // è·å–è¾“å…¥èŠ‚ç‚¹
        let inputNode = audioEngine.inputNode
        let recordingFormat = inputNode.outputFormat(forBus: 0)
        
        // åˆ›å»ºéŸ³é¢‘æ–‡ä»¶ï¼ˆç”¨äºå´©æºƒæ¢å¤ï¼‰
        if let url = tempAudioFileURL {
            audioFile = try? AVAudioFile(forWriting: url, settings: recordingFormat.settings)
        }
        
        // å®‰è£… Tap èŠ‚ç‚¹
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: recordingFormat) { [weak self] buffer, _ in
            // å‘é€åˆ°è¯­éŸ³è¯†åˆ«
            self?.recognitionRequest?.append(buffer)
            
            // å†™å…¥ç£ç›˜ï¼ˆå´©æºƒæ¢å¤ï¼‰
            try? self?.audioFile?.write(from: buffer)
            
            // è®¡ç®—éŸ³é¢‘ç”µå¹³
            self?.processAudioLevel(buffer: buffer)
        }
        
        // å¼€å§‹è¯†åˆ«ä»»åŠ¡
        recognitionTask = recognizer.recognitionTask(with: request) { [weak self] result, error in
            Task { @MainActor in
                if let result = result {
                    let text = result.bestTranscription.formattedString
                    
                    if result.isFinal {
                        self?.onFinalResult?(text)
                        // æœ€ç»ˆç»“æœåæ¸…ç† task
                        self?.recognitionTask = nil
                    } else {
                        self?.onPartialResult?(text)
                    }
                }
                
                if let error = error {
                    // åªæœ‰éå–æ¶ˆé”™è¯¯æ‰æŠ¥å‘Šï¼ˆç”¨æˆ·ä¸»åŠ¨å–æ¶ˆä¸ç®—é”™è¯¯ï¼‰
                    let nsError = error as NSError
                    if nsError.code != Self.speechRecognizerCancelledErrorCode {
                        self?.onError?(error)
                    }
                    self?.recognitionTask = nil
                }
            }
        }
        
        // å¯åŠ¨å¼•æ“
        audioEngine.prepare()
        try audioEngine.start()
        
        isRecording = true
        logger.info("ğŸ™ï¸ Recording started")
    }
    
    /// åœæ­¢å½•éŸ³ï¼ˆæ­£å¸¸ç»“æŸï¼Œç­‰å¾…æœ€ç»ˆè¯†åˆ«ç»“æœï¼‰
    func stopRecording() -> String? {
        guard isRecording else { return nil }
        
        // åœæ­¢éŸ³é¢‘å¼•æ“
        audioEngine?.stop()
        audioEngine?.inputNode.removeTap(onBus: 0)
        
        // ç»“æŸè¯†åˆ«è¯·æ±‚ï¼ˆä¸è¦ cancelï¼Œè®©å®ƒè‡ªç„¶å®Œæˆï¼‰
        recognitionRequest?.endAudio()
        // æ³¨æ„ï¼šä¸è°ƒç”¨ recognitionTask?.cancel()ï¼Œç­‰å¾…æœ€ç»ˆç»“æœ
        
        // å…³é—­éŸ³é¢‘æ–‡ä»¶
        audioFile = nil
        
        // æ¸…ç†å¼•æ“ï¼ˆä½†ä¿ç•™ recognitionTask ç­‰å¾…å®Œæˆï¼‰
        recognitionRequest = nil
        audioEngine = nil
        
        isRecording = false
        logger.info("â¹ï¸ Recording stopped")
        
        return tempAudioFileURL?.path
    }
    
    /// å–æ¶ˆå½•éŸ³ï¼ˆç”¨æˆ·ä¸»åŠ¨å–æ¶ˆï¼Œä¸¢å¼ƒç»“æœï¼‰
    func cancelRecording() {
        // å³ä½¿ä¸åœ¨å½•éŸ³çŠ¶æ€ï¼Œä¹Ÿè¦å°è¯•å–æ¶ˆå¯èƒ½æ®‹ç•™çš„ä»»åŠ¡
        guard isRecording || recognitionTask != nil else { return }
        
        // åœæ­¢éŸ³é¢‘å¼•æ“
        audioEngine?.stop()
        audioEngine?.inputNode.removeTap(onBus: 0)
        
        // å–æ¶ˆè¯†åˆ«ä»»åŠ¡
        recognitionTask?.cancel()
        recognitionRequest?.endAudio()
        
        // å…³é—­éŸ³é¢‘æ–‡ä»¶
        audioFile = nil
        
        // æ¸…ç†
        recognitionRequest = nil
        recognitionTask = nil
        audioEngine = nil
        
        isRecording = false
        logger.info("ğŸš« Recording cancelled")
        
        // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        cleanupTempFile()
    }
    
    /// æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    func cleanupTempFile() {
        if let url = tempAudioFileURL {
            try? FileManager.default.removeItem(at: url)
            tempAudioFileURL = nil
        }
    }
    
    // MARK: - Private
    
    private func createTempAudioFileURL() -> URL {
        let tempDir = FileManager.default.temporaryDirectory
        let fileName = "spoke_\(UUID().uuidString).caf"
        return tempDir.appendingPathComponent(fileName)
    }
    
    private func processAudioLevel(buffer: AVAudioPCMBuffer) {
        guard let channelData = buffer.floatChannelData?[0] else { return }
        
        let frameLength = Int(buffer.frameLength)
        // ä½¿ç”¨ RMS (å‡æ–¹æ ¹) è®¡ç®—ï¼Œæ›´èƒ½åæ˜ å¬æ„Ÿå“åº¦
        var sumSquares: Float = 0
        
        // é™é‡‡æ ·ä»¥æé«˜æ€§èƒ½ (æ¯ 4 ä¸ªé‡‡æ ·ç‚¹å–ä¸€ä¸ª)
        let strideStep = 4
        for i in stride(from: 0, to: frameLength, by: strideStep) {
            let sample = channelData[i]
            sumSquares += sample * sample
        }
        
        let rms = sqrt(sumSquares / Float(frameLength / strideStep))
        
        // éçº¿æ€§æ”¾å¤§ï¼š
        // 1. åŸºç¡€æ”¾å¤§å€æ•° 5.0
        // 2. åŠ ä¸Šä¸€ä¸ªéçº¿æ€§åˆ†é‡ sqrt(rms) * 2.0 æå‡å°éŸ³é‡è¡¨ç°
        // 3. é™åˆ¶åœ¨ 0.01 - 1.0 ä¹‹é—´ (ä¿ç•™æå°å€¼é¿å…å®Œå…¨é™æ­¢)
        var level = (rms * 5.0) + (sqrt(rms) * 2.0)
        
        // æ·»åŠ ä¸€ç‚¹éšæœºæŠ–åŠ¨ï¼Œè®©æ³¢å½¢åœ¨è¯´è¯æ—¶æ›´ç”ŸåŠ¨
        if level > 0.1 {
            level += Float.random(in: -0.05...0.05)
        }
        
        let finalLevel = min(max(level, 0.02), 1.0)
        
        Task { @MainActor in
            onAudioLevelUpdate?(finalLevel)
        }
    }
}

// MARK: - Errors

enum AudioRecorderError: LocalizedError {
    case recognizerNotAvailable
    case engineCreationFailed
    case requestCreationFailed
    case permissionDenied
    
    var errorDescription: String? {
        switch self {
        case .recognizerNotAvailable:
            return "è¯­éŸ³è¯†åˆ«å™¨ä¸å¯ç”¨"
        case .engineCreationFailed:
            return "éŸ³é¢‘å¼•æ“åˆ›å»ºå¤±è´¥"
        case .requestCreationFailed:
            return "è¯†åˆ«è¯·æ±‚åˆ›å»ºå¤±è´¥"
        case .permissionDenied:
            return "æƒé™è¢«æ‹’ç»"
        }
    }
}
