import AVFoundation
import Speech
import os

/// SFSpeechRecognizer å®ç°
/// é€‚ç”¨äº macOS 15+ / iOS 10+
/// å›é€€æ–¹æ¡ˆï¼Œå½“ SpeechAnalyzer ä¸å¯ç”¨æ—¶ä½¿ç”¨
@MainActor
final class SFSpeechProvider: TranscriptionProvider {
    
    // MARK: - Constants
    
    private static let cancelledErrorCode = 216
    
    // MARK: - Properties
    
    let identifier = "sf_speech_recognizer"
    let displayName = "Apple Dictation"
    
    let capabilities: TranscriptionCapability = [.realtime, .punctuation]
    
    var locale: Locale {
        didSet {
            speechRecognizer = SFSpeechRecognizer(locale: locale)
        }
    }
    
    var isAvailable: Bool {
        speechRecognizer?.isAvailable ?? false
    }
    
    var supportedLocales: [Locale] {
        SFSpeechRecognizer.supportedLocales().map { Locale(identifier: $0.identifier) }
    }
    
    var onResult: ((TranscriptionResult) -> Void)?
    var onError: ((Error) -> Void)?
    
    // MARK: - Private
    
    private let logger = Logger(subsystem: "com.spokeanywhere", category: "SFSpeechProvider")
    private var speechRecognizer: SFSpeechRecognizer?
    private var recognitionRequest: SFSpeechAudioBufferRecognitionRequest?
    private var recognitionTask: SFSpeechRecognitionTask?
    
    // MARK: - Init
    
    init(locale: Locale = Locale(identifier: "zh-CN")) {
        self.locale = locale
        self.speechRecognizer = SFSpeechRecognizer(locale: locale)
    }
    
    // MARK: - TranscriptionProvider
    
    func requestAuthorization() async -> Bool {
        await withCheckedContinuation { continuation in
            SFSpeechRecognizer.requestAuthorization { status in
                continuation.resume(returning: status == .authorized)
            }
        }
    }
    
    func prepare() async throws {
        guard let recognizer = speechRecognizer, recognizer.isAvailable else {
            throw TranscriptionError.notAvailable
        }
        
        // åˆ›å»ºè¯†åˆ«è¯·æ±‚
        recognitionRequest = SFSpeechAudioBufferRecognitionRequest()
        guard let request = recognitionRequest else {
            throw TranscriptionError.engineNotReady
        }
        
        request.shouldReportPartialResults = true
        request.addsPunctuation = true
        request.taskHint = .dictation
        
        // å¯åŠ¨è¯†åˆ«ä»»åŠ¡
        recognitionTask = recognizer.recognitionTask(with: request) { [weak self] result, error in
            Task { @MainActor in
                self?.handleRecognitionResult(result: result, error: error)
            }
        }
        
        logger.info("âœ… SFSpeechProvider prepared")
    }
    
    func process(buffer: AVAudioPCMBuffer) throws {
        guard let request = recognitionRequest else {
            throw TranscriptionError.engineNotReady
        }
        request.append(buffer)
    }
    
    func finishProcessing() async throws {
        recognitionRequest?.endAudio()
        
        // ç­‰å¾…æœ€ç»ˆç»“æœ
        var waitTime = 0
        let maxWait = 2000
        let interval = 100
        
        while waitTime < maxWait && recognitionTask != nil {
            try? await Task.sleep(for: .milliseconds(interval))
            waitTime += interval
        }
        
        logger.info("âœ… SFSpeechProvider finished processing")
    }
    
    func cancel() {
        recognitionTask?.cancel()
        recognitionRequest?.endAudio()
        cleanup()
        logger.info("ğŸš« SFSpeechProvider cancelled")
    }
    
    func reset() {
        cleanup()
        logger.info("ğŸ”„ SFSpeechProvider reset")
    }
    
    // MARK: - Private
    
    private func handleRecognitionResult(result: SFSpeechRecognitionResult?, error: Error?) {
        if let result = result {
            let text = result.bestTranscription.formattedString
            let resultType: TranscriptionResultType = result.isFinal ? .final : .partial
            let confidence = result.bestTranscription.segments.last?.confidence
            
            onResult?(TranscriptionResult(
                text: text,
                type: resultType,
                confidence: confidence
            ))
            
            if result.isFinal {
                recognitionTask = nil
            }
        }
        
        if let error = error {
            let nsError = error as NSError
            // å¿½ç•¥ç”¨æˆ·å–æ¶ˆé”™è¯¯
            if nsError.code != Self.cancelledErrorCode {
                onError?(error)
            }
            recognitionTask = nil
        }
    }
    
    private func cleanup() {
        recognitionRequest = nil
        recognitionTask = nil
    }
}

// MARK: - Provider Info

extension SFSpeechProvider {
    static var info: TranscriptionProviderInfo {
        TranscriptionProviderInfo(
            identifier: "sf_speech_recognizer",
            displayName: "Apple Dictation",
            description: "ç³»ç»Ÿå†…ç½®è¯­éŸ³è¯†åˆ«ï¼Œéœ€è¦ç½‘ç»œï¼Œé€‚ç”¨äº macOS 15+",
            capabilities: [.realtime, .punctuation],
            minOSVersion: "macOS 15.0",
            isAvailable: SFSpeechRecognizer()?.isAvailable ?? false
        )
    }
}
