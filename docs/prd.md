# 1. 产品概述
## 1.1 产品名称（暂定）
SpokenAnyWhere（Mac 版）—— 一款面向创作者与知识工作者的 **快捷听写 + 文本智能处理**工具。
## 1.2 背景 / 问题
* 用户在写作、开会、在线通话时，常常需要把大量语音内容转成文本，并做进一步规范化（去掉口头语、加标点、格式化为摘要等）。
* 现有方案存在几个痛点：
  * 需要在浏览器 / 多个 App 之间来回切换，打断工作流。
  * 模型碎片化：系统自带听写、本地 Whisper、云端 ASR / LLM 各自为政，难以组合。
  * 对“转写后的文本二次处理”（比如根据自定义 Prompt 清洗文字）支持较弱。
* 本产品希望通过单一桌面应用，整合 **本地模型 + 远程 API 模型（Gemini 等）**，并提供统一的快捷键和 Pipeline，让用户“按一个键，说完就得到高质量文本”。
## 1.3 产品目标
1. 提供一套 **统一、可配置的听写管线**：
   * 音频 → 听写模型 → 文本 → AI 提示处理 → 输出 / 剪贴板。
2. 支持多种模型来源：
   * 本地模型（Apple STT、Whisper、本地 Nvidia 模型等）。
   * 远程 API 模型（如 `gemini-2.5-flash`、`gemini-2.5-flash-lite` 等）。
3. 让用户可以像选「输入法」一样，简单选择、切换、测试模型和 AI 提供商。
4. 以 **系统级快捷键** 融入用户任意 App 的输入流程中。
## 1.4 用户画像
* **内容创作者**：UP 主、播客主、视频博主，需要把口播稿快速转成可编辑文本。
* **知识工作者 / 学生**：会议记录、上课笔记、访谈整理。
* **程序员 / 写作者**：一边说一边写代码 / 文档，希望有结构化输出（列表、摘要）。
---
# 2. 概念与术语
* **听写模型（Transcription Model）**：把语音转换为原始文本的模型。
  * 来源可以是本地（Apple STT / Whisper）或远程 API。
* **AI 提供商（AI Provider）**：提供文本处理 / LLM 能力的服务商。
  * 例如：Google Gemini（模型：Gemini 2.5 Flash / Flash Lite）。
* **AI 提示（Prompt）**：用户定义的文字说明，指导 LLM 对转写文本做二次加工。
* **「思考」模式**：对支持长推理 / 深度推理的模型（如 Gemini 2.5 Flash）启用更强推理能力的开关。
---
# 3. 范围与非目标
## 3.1 本期范围（MVP）
* Mac 桌面 App（Intel + Apple Silicon）。
* 支持：
  * 实时听写（按住快捷键说话，松开即转成文本）。
  * 文件转写（导入音频文件批量处理）。
  * 本地 + 远程模型配置与切换。
  * 基本历史记录管理。
  * AI 提示配置、Gemini Provider 管理与测试。
* UI 以「系统设置风格」多栏结构为主。
* **交互核心**：采用「灵动岛」风格悬浮胶囊，提供极简但明确的状态反馈。

## 3.2 非目标（暂不实现）
* iOS / Windows 客户端。
* 实时字幕叠加在任意窗口 (我确实需要实时字幕)
* 协作 / 多人共享项目。
* 超复杂的项目管理（多层文件夹、标签系统）。
---
# 4. 信息架构 & 导航
侧边栏菜单（从上到下）：
-1. **下载 iOS 应用**（跳转链接）- 这个不要
2. **常规设置**
3. **听写模型**
4. **转录文件**
5. **历史记录**
6. **快捷键**
7. **AI 提示**
8. **联系我们**
每个菜单对应一个主内容区域页面（Detail View）。
---
# 5. 用户场景 & User Stories
### 场景 A：实时听写 + 自动清洗文本
> 用户在 Notion / Word 中写文档，希望一边说一边生成排版好的文字。
* 作为用户，我希望通过一个全局快捷键触发录音，这样我在任何 App 里都能快速开始说话。
* 作为用户，我希望说完松开键后，自动得到 **去掉口头语、加标点并改成通顺书面语** 的文本，并直接插入到我当前光标位置。
* 作为用户，我希望可以自己配置一段 Prompt，来决定“如何处理听写文本”。

### 场景 B：上下文感知与多模态反馈
* 作为用户，我希望在录音时能看到一个悬浮的「胶囊窗口」，明确告诉我当前正在对哪个 App（如 Xcode）说话。
* 作为用户，我希望当我切换到 Xcode 时，它自动知道要生成“代码注释风格”；切到微信时，自动变成“口语风格”。

### 场景 C：数据安全与崩溃恢复
* 作为用户，我希望即使电脑死机或断电重启，刚才录的那段话还在，应用能提示我恢复它。
* 作为用户，当网络断开导致 AI 处理失败时，我希望能自动获得原始转写文本，而不是报错丢失。

### 场景 D：选择合适的模型
> 用户有 Apple 芯片机器，也有 Gemini API Key，希望综合使用。
* 作为用户，我希望在一个页面上看到所有可用模型：Apple、本地 Whisper、Gemini Flash、Flash Lite 等，并且了解各自优劣（速度 / 准确度 / 延迟）。
* 作为用户，我希望一键切换默认听写模型（Apple ↔ Whisper）。
* 作为用户，我希望对 LLM 处理选择 Gemini 2.5 Flash，并根据场景切换成 Flash Lite（低延迟）。
### 场景 C：按文件批量转录
* 作为用户，我希望把会议录音 / 访谈音频拖进 App，一次转成文本，并可以统一按我的 Prompt 清洗。
* 作为用户，我希望在转录完成后，能在历史中搜索这些记录。
### 场景 D：配置与测试 AI 提供商
* 作为用户，我希望在 “AI 提示” 页面中添加自己的 Gemini API Key，并验证“连接已测试”。
* 作为用户，我希望看到不同模型卡片（Gemini 2.5 Flash / Flash Lite）的说明和标签，根据需要选择一个并开启“思考”开关。
---
# 6. 功能需求（按页面）
## 6.1 常规设置
### 6.1.1 行为选项
* [F-1][P0] **登录时启动**
* [F-2][P0] **在程序坞中显示**
* [F-3][P0] **在状态栏中显示图标**
* [F-4][P0] **使用 Escape 键取消录音**（开关）
* [F-5][P1] **应用界面语言**（暂定简体中文，预留扩展能力）
### 6.1.2 麦克风优先级
* [F-6][P0] 展示所有可用音频输入设备列表：
  * 支持拖拽排序。
  * 列表中显示当前连接状态，若设备断开显示灰色。
* [F-7][P0] 实时录音时，按优先顺序自动选择第一个可用设备。
* [F-8][P1] 用户手动指定设备时，优先级列表自动更新。
### 6.1.3 输出行为配置
* [F-43][P0] **输出模式**（下拉选择）：
  * 仅复制到剪贴板
  * 自动粘贴到光标位置（默认）
  * 两者都执行
* [F-44][P0] **保留原始转写**（开关，默认开启）：
  * 开启时，历史记录同时存储原始转写文本和 AI 处理后文本。
  * 用户可在历史详情中切换查看。
* [F-45][P1] **自动粘贴失败回退**：
  * 若模拟键盘输入失败（如目标 App 不支持），自动回退到剪贴板模式并提示用户。

### 6.1.4 悬浮胶囊交互 (Floating Capsule)
* [F-54][P0] **录音状态反馈**：
  * 样式：屏幕居中或跟随光标的圆角胶囊（类似 Dynamic Island）。
  * 左侧：显示 **当前目标 App 图标**（如 Xcode、Notion），明确上下文。
  * 中间：动态声波纹路（随音量跳动）+ 录音时长计时。
  * 右侧：停止/完成按钮。
* [F-55][P0] **处理状态反馈**：
  * 录音结束 → 胶囊收缩为加载状态（呼吸灯/Loading 圈）。
  * 成功 → 胶囊短暂变绿/打钩，随后消失。
  * 失败 → 胶囊变红并显示简短错误（如“AI 无响应，已转存”）。

## 6.2 听写模型页面
### 6.2.1 模型列表展示
* [F-9][P0] 顶部筛选：
  * 「全部」「在线」「本地」「API」等 Tab。
* [F-10][P0] 模型卡片字段（示例）：
  * 图标（Apple / Nvidia / Google / Whisper 等）
  * 名称：如「Apple 语音分析器」「Nvidia Parakeet」「Whisper Large V3 Turbo」
  * 标签：**多语言 / 实时 / 本地 / 云端 / 低延迟 / 高精度**等
  * 体积/大小（本地模型）
  * 连接状态（远程 API 模型：未连接 / 已连接）
  * 当前使用标记（“当前模型”徽章或蓝色边框）
### 6.2.2 本地模型管理
* [F-11][P0] 对本地模型：
  * 支持「下载 / 删除」操作。
  * 显示下载进度和状态。
* [F-12][P0] 下载完成后可选为默认模型。
### 6.2.3 远程 API 模型（如 Gemini 2.5 Flash / Flash Lite）
* [F-13][P1] 对模型 `location=RemoteAPI`（如 Gemini）：
  * 如果对应 Provider 未配置 API Key，卡片上显示“连接”按钮。
  * 点击“连接”弹出 **AI 提供商配置弹窗**：
    * 输入：API Key、可选 Base URL、默认模型选择。
    * 支持「测试连接」按钮。
* [F-14][P1] 测试成功后，模型卡片显示「连接已测试」状态。
* [F-15][P1] Gemini 系列模型卡片额外字段：
  * Flash：标签“多模态 / 在线 / 云端 / 推荐”
  * Flash Lite：标签“低延迟 / 在线 / 云端”
  * “思考”开关只对支持深度推理的模型可用（如 Flash）。
### 6.2.4 默认模型 & 测试
* [F-16][P0] 用户可单击卡片选择默认听写模型（单选）。
* [F-17][P1] 每个模型支持“测试”功能：
  * 点击后打开弹窗，提示用户：
    * 「按住 ⌥+R 说话测试模型，或按 ⌥+R 切换录音开/关」
    * 中间为一个实时更新的文本框，展示转写结果。
  * 使用当前选中模型进行实时转写。
## 6.3 转录文件页面
* [F-18][P2] 支持拖拽一个或多个音频 / 视频文件进入列表。
* [F-19][P2] 每个任务显示：
  * 文件名、时长（如可获取）、当前进度、使用的听写模型、状态（排队中 / 转写中 / 已完成 / 失败）。
* [F-20][P2] 支持指定：
  * 使用的听写模型（默认使用全局默认）。
  * 使用的输出语言（如支持）。
  * 是否应用 AI 提示处理。
* [F-21][P2] 转写完成后，用户可以：
  * 查看全文。
  * 一键复制 / 导出为 .txt / .md。
  * 发送到历史记录。
## 6.4 历史记录页面
* [F-22][P1] 按时间倒序列出历史记录。
* [F-23][P1] 每条记录包括：
  * 创建时间。
  * 使用的听写模型 + AI 提供商（如果有）。
  * 原始转写文本 / AI 处理后文本（可切换查看）。
  * 文本前几行预览。
* [F-24][P1] 支持：
  * 搜索（按关键字）。
  * 过滤（按模型 / 日期）。
  * 查看详情（打开侧边或弹窗）。
  * 复制文本 / 导出文件。
  * 标记收藏 / 删除。
## 6.5 快捷键页面
### 6.5.1 录音快捷键
* [F-25][P0] 显示当前录音快捷键（默认：⌥ + R）。
* [F-26][P0] 提供设置组件：
  * 用户点击「更改」，开始录制组合键。
  * 捕捉按键后，展示组合，并注册为全局快捷键。
  * 检测快捷键冲突：若与系统或常用 App 冲突，显示警告提示。
* [F-27][P0] 模式选择：
  * 「按住」：按住即录音，松开即结束。
  * 「切换」：按一次开始，再按一次停止。
### 6.5.2 测试区域
* [F-28][P0] 页面下半部分是一个测试文本框，提示：
  * 「请首先点击下方的文本框」。
  * 用户按下已设置的快捷键时，应用执行录音 → 转写 → 将文本填入该框，本质是验证快捷键生效及录音管线正常。
## 6.6 AI 提示页面
### 6.6.1 主提示配置
* [F-29][P0] 中间大卡片显示「主提示」，内容支持多行：
  示例默认文案（可编辑）：
  * “处理普通讲话的文本：
    * 去掉口头语
    * 添加适当标点
    * 使用逆文本正规化（Inverse Text Normalization）…”
* [F-30][P0] 用户可开启 / 关闭“启用 AI 文本处理”总开关。
* [F-31][P0] 快捷展示当前录音快捷键（作为提醒）。

### 6.6.2 上下文 Prompt 规则 (App-Specific)
* [F-56][P1] **Prompt 拼接逻辑**：
  * `最终 Prompt` = `[全局核心 Prompt]` + `[App 专属规则]`。
* [F-57][P1] **App 规则配置**：
  * 列表展示已配置的 App 规则。
  * 添加规则：
    * 选择目标 App（从系统运行列表中选，或手动输入 Bundle ID）。
    * 输入该 App 的附加 Prompt（如：“使用 Markdown 格式，提取 TODO”）。
  * 示例预设：
    * IDE 类（Xcode/VSCode）："代码注释风格，保留英文术语"。
    * 聊天类（微信/Slack）："口语化，添加适当 emoji"。

### 6.6.3 AI 提供商管理弹窗
* [F-32][P1] 右侧按钮「添加 API 密钥 / AI 提供商」：
  * 弹出 AI 提供商管理窗口。
* [F-33][P1] 列表展示已添加的 Provider 卡片，例如：
  * Google Gemini（当前模型：gemini-2.5-flash-latest）。
* [F-34][P1] 每个 Provider 卡片字段：
  * Provider Logo + 名称。
  * 当前默认模型名。
  * “连接已测试”状态（绿色标记）。
  * 「编辑」按钮，打开配置表单：
    * API Key（必填，隐藏显示）。
    * 默认模型选择（下拉列表，含 Flash / Flash Lite）。
    * 测试连接按钮：调用 Provider 测试接口。
* [F-35][P1] 可以添加多个 Provider，标记一个为 **当前用于 AI 提示处理**的 Provider。
### 6.6.3 LLM 模型选择与“思考”开关
* [F-36][P1] 在 AI 提供商弹窗中，显示 Provider 下属模型列表（类似你发的 Gemini Flash / Lite 卡片）。
* [F-37][P1] 用户可以：
  * 选择一个模型作为默认 LLM 处理模型。
  * 对支持 “思考” 模型，勾选全局“思考”开关。
* [F-38][P1] 当用户启用“思考”：
  * 后端在调用该模型时使用增强推理模式（具体实现由后台控制，但 PRD 定义行为：预计更高质量、稍高延迟）。
## 6.7 联系我们页面
* [F-39][P2] 提供反馈入口：
  * 反馈类型（Bug / 建议 / 其他）。
  * 文本输入框。
  * 可选附带日志（勾选框）。
* [F-40][P2] 点击提交后：
  * 显示“提交成功”Toast。
  * 通过指定渠道发送（邮件 / 后端 API）。

## 6.8 实时字幕 (Overlay)
* [F-58][P2] **实时字幕覆盖层**：
  * 开启后，在屏幕底部或顶部显示一个半透明覆盖层。
  * 实时显示听写文本（Streaming），无需手动开始/停止录音（VAD 触发）。
  * 适用于观看无字幕视频或在线会议。
---
# 7. 核心交互流程
## 7.1 实时听写 Pipeline
**触发：** 用户在任意 App 内按下全局快捷键。
1. App 捕获全局快捷键；若当前状态空闲 → 进入「录音中」：
   * 系统请求麦克风权限（第一次）。
   * UI 通知（状态栏图标亮起 / 小浮层）。
2. `AudioEngine` 开始采集音频。
3. 选中听写模型（从 `ModelRegistry` 获取）。
   * 若模型不可用（下载中 / API 未连接），则：
     * 回退到系统默认模型，或提示错误。（具体策略在 PRD 中可约定为：优先系统 STT）
4. 听写模型输出 **原始文本**（可流式）。
5. 若 AI 提示处理开启：
   * 将原始文本 + 用户主 Prompt 发送给当前 Provider + LLM 模型。
   * 根据“思考”开关决定是否启用增强模式。
   * 得到 **处理后的文本**。
6. 将处理后的文本：
   * 写入剪贴板。
   * 尽可能模拟键盘输入，在当前光标位置插入文本（可配置）。
7. 将本次结果写入历史记录（包含原始文本 + 处理后文本 + 使用模型信息）。
## 7.2 文件转录 Pipeline
1. 用户在「转录文件」页面添加音频文件。
2. 系统为每个文件创建转录任务：
   * 选择用于听写的模型。
   * 是否应用 AI 提示处理。
3. 后台串行或并行执行：
   * 音频 → 听写 → 文本 → （可选）AI 提示处理。
4. 完成后：
   * 更新任务状态。
   * 写入历史记录。
   * 支持导出 / 打开 / 复制。
---
# 8. 多模型配置与管理（产品视角）
> 以下内容是产品对“多模型体系”的抽象要求，供架构设计参考（不是具体代码）。
## 8.1 概念约束
* 每个模型必须有全局唯一 `modelId`（如 `gemini-2.5-flash`、`apple-speech-zh-cn` 等）。
* 模型挂在某个 Provider 下（Apple / Google / Whisper Local 等）。
* 模型类型（kind）分两大类：
  * `Transcription`：用于语音转文字。
  * `LLM`：用于文本处理 / Prompt 后处理。
## 8.2 配置来源
* **内置配置文件**：
  * 列出默认 Provider（如 Google）及其模型（Gemini Flash / Lite）。
  * 列出本地模型入口（Apple STT / Whisper 等）。
* **用户配置**：
  * Provider 的 API Key。
  * 用户新增的自定义 Provider（如自建 OpenAI 兼容接口）。
  * 用户选择的默认模型、思考开关、偏好设置。
产品要求：
* [F-41][P0] 应用启动时自动合并内置配置和用户配置。
* [F-42][P1] 新版本增加内置模型时，不影响用户已有 Provider 配置。
## 8.3 UI 行为一致性
* 所有模型卡片表现形式统一：
  * 图标 + 名称 + 标签 + 指标 + 主操作按钮（连接 / 下载 / 设置为默认）。
* 对于远程模型：
  * 在模型卡片上显示默认 Provider 状态（是否已连接）。
  * Provider 级别的配置和测试在统一弹窗中完成。
---
# 9. 权限 & 安全
* [NF-1] 所有音频数据：
  * 本地模型：完全在本机处理，不上传。
  * 远程 API 模型（包括 Gemini）：
    * 明确在 UI 上标记“将发送到云端处理”。
* [NF-8] **黑匣子录音与崩溃恢复**：
  * **实时落盘**：录音过程中，音频流必须实时写入本地临时文件（Stream to disk），而非仅保存在内存中。
  * **崩溃恢复**：App 启动时自动扫描临时目录，若发现未归档的录音文件，弹窗提示用户“发现未完成的录音”，支持一键转写或保存。
  * **优雅降级**：
    * 当 AI API 请求失败/超时 → 自动回退到仅使用听写模型结果。
    * 当听写模型也失败 → 提示保存原始音频文件。
* [NF-2] API Key 安全：
  * 以安全方式保存（macOS Keychain 或加密文件）。
  * 在 UI 中不明文显示完整 Key（中间部分打码）。
* [NF-3] 日志收集：
  * 日志默认只包含技术信息，不记录完整转写内容。
  * 如需上传日志，必须弹框明确征得用户同意。
---
# 10. 性能与非功能需求
* [NF-4] 实时听写延迟：
  * 本地模型：在 Apple Silicon 上，应保证 1 秒语音 ≤ 1 秒处理速度。
  * 远程模型：端到端延迟（说完到文字输出）建议 < 2–3 秒（网络情况良好）。
* [NF-5] 内存占用：
  * 下载大模型时可占用较多，但运行实时听写时应保持稳定。
* [NF-6] 稳定性：
  * 模型下载 / API 调用失败时，提供明确错误提示而非崩溃。
  * 听写过程中网络波动，要有超时和重试策略（产品层要求：出现问题时给出可理解的提示）。
* [NF-7] 录音时长限制：
  * 实时听写最大时长：**60 分钟**。
  * 超时处理：自动停止录音并处理已录制内容。
  * 提醒机制：录音达到 50 分钟时，显示剩余时间提示（状态栏 / 浮层）。
  * 文件转录不受此限制（由文件本身时长决定）。
---
# 11. 度量指标（Metrics）
* 日活 / 周活用户数。
* 单日听写次数、平均时长。
* 模型使用分布（Apple vs Whisper vs Gemini）。
* AI 提示处理开启率。
* 失败率（转写失败 / LLM 调用失败）。
---
# 12. 版本规划（粗略）
* **v1.0**（P0 功能）
  * 实时听写 + 快捷键（F-25~F-28）。
  * 本地 Apple STT + 1 个本地模型（Whisper）（F-9~F-12, F-16）。
  * 常规设置 + 输出行为配置（F-1~F-8, F-43~F-45）。
  * AI 提示主配置（F-29~F-31）。
  * 基础 Onboarding 流程。
* **v1.1**（P1 功能）
  * Gemini Provider 集成（Flash / Flash Lite）（F-13~F-15, F-17）。
  * AI 提供商管理（F-32~F-38）。
  * 历史记录完整功能（F-22~F-24）。
  * 配置合并与版本兼容（F-41~F-42）。
* **v1.x**（P2 功能）
  * 文件转录完整功能（F-18~F-21）。
  * 联系我们 / 反馈（F-39~F-40）。
  * 增强转录文件体验（队列、并发控制）。
  * 更多模型 / Provider 支持。
  * 更丰富的文本模板（会议纪要、概要、子弹列表等）。
---
# 13. Onboarding 流程
## 13.1 首次启动向导（3 步）
* [F-46][P0] **步骤 1：欢迎 & 麦克风权限**
  * 展示产品简介（一句话 + 图标）。
  * 请求麦克风权限，附带友好说明：「SpokenAnyWhere 需要麦克风权限来进行语音转文字」。
  * 若用户拒绝，显示如何在系统设置中开启的引导。
* [F-47][P0] **步骤 2：选择默认听写模型**
  * 展示可用的本地模型列表（Apple STT / Whisper）。
  * 推荐默认选项（Apple STT，无需下载）。
  * 用户可跳过，使用系统默认。
* [F-48][P0] **步骤 3：快捷键确认**
  * 展示默认快捷键（⌥ + R）。
  * 提供「立即试试」按钮，让用户体验一次录音。
  * 完成后进入主界面。
## 13.2 渐进式提示
* [F-49][P1] **首次使用 AI 处理时**：
  * 若 AI 处理开关开启但未配置 Provider，弹出提示：
    * 「配置 AI 提供商以启用智能文本处理」
    * 提供「去配置」和「暂不」按钮。
* [F-50][P1] **首次使用快捷键时**：
  * 在状态栏或浮层显示操作提示：
    * 「按住 ⌥+R 说话，松开即转写」（按住模式）
    * 「按 ⌥+R 开始/停止录音」（切换模式）
  * 3 秒后自动消失，或用户操作后消失。
* [F-51][P1] **辅助功能权限提示**（如需模拟键盘输入）：
  * 首次尝试自动粘贴时，若权限不足，引导用户开启：
    * 「需要辅助功能权限以自动插入文本到光标位置」
    * 提供「打开系统设置」按钮。
## 13.3 权限被拒绝的降级体验
* [F-52][P1] **麦克风权限被拒绝**：
  * 实时听写功能不可用，显示明确提示。
  * 文件转录功能仍可使用。
* [F-53][P1] **辅助功能权限被拒绝**：
  * 自动粘贴不可用，回退到「仅复制到剪贴板」模式。
  * 在设置页面显示权限状态和引导。
---
